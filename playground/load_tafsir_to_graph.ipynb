{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Loading Tafsir Data into Quran Knowledge Graph\n",
                "\n",
                "This notebook loads tafsir data from SQLite files into the Kuzu graph database, creating Tafsir nodes and connecting them to Verse nodes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "import kuzu\n",
                "import os\n",
                "import re\n",
                "import pandas as pd\n",
                "import time\n",
                "import sqlite3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize the Database"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Initialize the database\n",
                "db_path = \"quran_graph_db\"\n",
                "if not os.path.exists(db_path):\n",
                "    print(f\"Creating new database at {db_path}\")\n",
                "    db = kuzu.Database(db_path)\n",
                "else:\n",
                "    print(f\"Using existing database at {db_path}\")\n",
                "    db = kuzu.Database(db_path)\n",
                "\n",
                "conn = kuzu.Connection(db)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load SQLite Extension"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Install and load SQLite extension if not already loaded\n",
                "try:\n",
                "    conn.execute(\"INSTALL sqlite\")\n",
                "    conn.execute(\"LOAD sqlite\")\n",
                "    print(\"SQLite extension installed and loaded\")\n",
                "except Exception as e:\n",
                "    print(f\"SQLite extension already loaded or error: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check for Existing Verse Table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Check if Verse table exists, if not create it\n",
                "try:\n",
                "    result = conn.execute(\"MATCH (v:Verse) RETURN count(v) AS count\").get_as_df()\n",
                "    verse_count = result.iloc[0]['count']\n",
                "    print(f\"Found {verse_count} existing verses in the database\")\n",
                "except Exception as e:\n",
                "    print(f\"Verse table not found, creating and loading from ayah.sqlite: {e}\")\n",
                "    # Attach ayah.sqlite and create Verse node table\n",
                "    conn.execute(\"ATTACH './raw_data/ayah.sqlite' as ayah (dbtype sqlite)\")\n",
                "    conn.execute(\"\"\"\n",
                "    CREATE NODE TABLE Verse (\n",
                "        id INT64,\n",
                "        surah_number INT64,\n",
                "        ayah_number INT64,\n",
                "        verse_key STRING PRIMARY KEY,\n",
                "        text STRING)\n",
                "    \"\"\")\n",
                "    conn.execute(\"COPY Verse FROM ayah.verses\")\n",
                "    verse_count = conn.execute(\"MATCH (v:Verse) RETURN count(v) AS count\").get_as_df().iloc[0]['count']\n",
                "    print(f\"Loaded {verse_count} verses into Kuzu\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Tafsir Node Table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Create Tafsir node table if it doesn't exist\n",
                "try:\n",
                "    result = conn.execute(\"MATCH (t:Tafsir) RETURN count(t) AS count\").get_as_df()\n",
                "    tafsir_count = result.iloc[0]['count']\n",
                "    print(f\"Found {tafsir_count} existing tafsir entries in the database\")\n",
                "except Exception as e:\n",
                "    print(f\"Tafsir table not found, creating: {e}\")\n",
                "    conn.execute(\"\"\"\n",
                "    CREATE NODE TABLE Tafsir (\n",
                "        id INT64 PRIMARY KEY,\n",
                "        verse_key STRING,\n",
                "        text STRING,\n",
                "        language STRING,\n",
                "        source STRING,\n",
                "        group_ayah_key STRING,\n",
                "        from_ayah STRING,\n",
                "        to_ayah STRING\n",
                "    )\n",
                "    \"\"\")\n",
                "    print(\"Created Tafsir node table\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create HAS_TAFSIR Relationship Table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Create HAS_TAFSIR relationship table if it doesn't exist\n",
                "try:\n",
                "    result = conn.execute(\"MATCH ()-[r:HAS_TAFSIR]->() RETURN count(r) AS count\").get_as_df()\n",
                "    rel_count = result.iloc[0]['count']\n",
                "    print(f\"Found {rel_count} existing HAS_TAFSIR relationships in the database\")\n",
                "except Exception as e:\n",
                "    print(f\"HAS_TAFSIR relationship table not found, creating: {e}\")\n",
                "    conn.execute(\"\"\"\n",
                "    CREATE REL TABLE HAS_TAFSIR (\n",
                "        FROM Verse TO Tafsir\n",
                "    )\n",
                "    \"\"\")\n",
                "    print(\"Created HAS_TAFSIR relationship table\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper Function to Extract Language and Source"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Function to extract language and source from filename\n",
                "def extract_language_and_source(filename):\n",
                "    # Remove 'tafsir_' prefix and '.sqlite' suffix\n",
                "    name = filename.replace('tafsir_', '').replace('.sqlite', '')\n",
                "    \n",
                "    # Extract language and source based on the filename\n",
                "    if 'english' in name:\n",
                "        language = 'english'\n",
                "        source = name.replace('_english', '')\n",
                "    elif 'indonesian' in name:\n",
                "        language = 'indonesian'\n",
                "        source = name.replace('_indonesian', '')\n",
                "    else:\n",
                "        # Default to English if no language specified\n",
                "        language = 'english'\n",
                "        source = name\n",
                "    \n",
                "    # Clean up source name\n",
                "    source = source.replace('_', ' ').title()\n",
                "    \n",
                "    return language, source"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Find Tafsir Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Load tafsir data from SQLite files\n",
                "raw_data_dir = './raw_data'\n",
                "tafsir_files = [f for f in os.listdir(raw_data_dir) if f.startswith('tafsir_') and f.endswith('.sqlite')]\n",
                "\n",
                "print(f\"Found {len(tafsir_files)} tafsir files to process:\")\n",
                "for file in tafsir_files:\n",
                "    language, source = extract_language_and_source(file)\n",
                "    print(f\"  - {file}: Language={language}, Source={source}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Process Tafsir Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Generate a unique ID for each tafsir entry\n",
                "try:\n",
                "    # Get the maximum ID from existing tafsir entries\n",
                "    max_id_result = conn.execute(\"MATCH (t:Tafsir) RETURN MAX(t.id) AS max_id\").get_as_df()\n",
                "    next_id = int(max_id_result.iloc[0]['max_id']) + 1 if not max_id_result.iloc[0]['max_id'] is None else 1\n",
                "    print(f\"Starting with ID {next_id} based on existing entries\")\n",
                "except Exception as e:\n",
                "    next_id = 1\n",
                "    print(f\"Starting with ID 1: {e}\")\n",
                "\n",
                "# Process each tafsir file\n",
                "for tafsir_file in tafsir_files:\n",
                "    file_path = os.path.join(raw_data_dir, tafsir_file)\n",
                "    language, source = extract_language_and_source(tafsir_file)\n",
                "    \n",
                "    # Check if this tafsir source has already been processed\n",
                "    try:\n",
                "        count_result = conn.execute(f\"MATCH (t:Tafsir) WHERE t.source = '{source}' AND t.language = '{language}' RETURN count(t) AS count\").get_as_df()\n",
                "        count = count_result.iloc[0]['count']\n",
                "        if count > 0:\n",
                "            print(f\"Skipping {tafsir_file} - Already processed {count} entries for {source} in {language}\")\n",
                "            continue\n",
                "    except Exception as e:\n",
                "        print(f\"Error checking for existing entries: {e}\")\n",
                "    \n",
                "    print(f\"Processing {tafsir_file} - Language: {language}, Source: {source}\")\n",
                "    \n",
                "    # Connect to the SQLite database\n",
                "    sqlite_conn = sqlite3.connect(file_path)\n",
                "    cursor = sqlite_conn.cursor()\n",
                "    \n",
                "    # Get the total number of entries\n",
                "    cursor.execute(\"SELECT COUNT(*) FROM tafsir\")\n",
                "    total_entries = cursor.fetchone()[0]\n",
                "    print(f\"  Total entries: {total_entries}\")\n",
                "    \n",
                "    # Fetch all tafsir entries\n",
                "    cursor.execute(\"SELECT ayah_key, group_ayah_key, from_ayah, to_ayah, ayah_keys, text FROM tafsir\")\n",
                "    \n",
                "    # Process in batches to avoid memory issues\n",
                "    batch_size = 1000\n",
                "    processed = 0\n",
                "    start_time = time.time()\n",
                "    \n",
                "    while True:\n",
                "        rows = cursor.fetchmany(batch_size)\n",
                "        if not rows:\n",
                "            break\n",
                "        \n",
                "        # Prepare data for insertion\n",
                "        tafsir_data = []\n",
                "        for row in rows:\n",
                "            ayah_key, group_ayah_key, from_ayah, to_ayah, ayah_keys, text = row\n",
                "            \n",
                "            # Skip entries with empty text\n",
                "            if not text:\n",
                "                continue\n",
                "                \n",
                "            tafsir_data.append({\n",
                "                'id': next_id,\n",
                "                'verse_key': ayah_key,\n",
                "                'text': text,\n",
                "                'language': language,\n",
                "                'source': source,\n",
                "                'group_ayah_key': group_ayah_key if group_ayah_key else '',\n",
                "                'from_ayah': from_ayah if from_ayah else '',\n",
                "                'to_ayah': to_ayah if to_ayah else ''\n",
                "            })\n",
                "            next_id += 1\n",
                "        \n",
                "        if not tafsir_data:\n",
                "            processed += len(rows)\n",
                "            continue\n",
                "            \n",
                "        # Create a temporary file for bulk loading\n",
                "        temp_df = pd.DataFrame(tafsir_data)\n",
                "        temp_csv = f\"temp_tafsir_{language}_{source.replace(' ', '_')}.csv\"\n",
                "        temp_df.to_csv(temp_csv, index=False)\n",
                "        \n",
                "        # Load data into Kuzu\n",
                "        conn.execute(f\"COPY Tafsir FROM '{temp_csv}' (HEADER = true, DELIMITER = ',', PARALLEL = FALSE)\")\n",
                "        \n",
                "        # Create relationships\n",
                "        for entry in tafsir_data:\n",
                "            try:\n",
                "                conn.execute(f\"\"\"\n",
                "                MATCH (v:Verse), (t:Tafsir)\n",
                "                WHERE v.verse_key = '{entry['verse_key']}' AND t.id = {entry['id']}\n",
                "                CREATE (v)-[:HAS_TAFSIR]->(t)\n",
                "                \"\"\")\n",
                "            except Exception as e:\n",
                "                print(f\"Error creating relationship for verse {entry['verse_key']}: {e}\")\n",
                "        \n",
                "        # Clean up\n",
                "        os.remove(temp_csv)\n",
                "        \n",
                "        processed += len(rows)\n",
                "        print(f\"  Processed {processed}/{total_entries} entries ({processed/total_entries*100:.1f}%)\")\n",
                "    \n",
                "    sqlite_conn.close()\n",
                "    \n",
                "    elapsed_time = time.time() - start_time\n",
                "    print(f\"  Completed in {elapsed_time:.2f} seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Graph Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Count the number of tafsir nodes and relationships\n",
                "tafsir_count = conn.execute(\"MATCH (t:Tafsir) RETURN count(t) AS count\").get_as_df().iloc[0]['count']\n",
                "rel_count = conn.execute(\"MATCH ()-[r:HAS_TAFSIR]->() RETURN count(r) AS count\").get_as_df().iloc[0]['count']\n",
                "\n",
                "print(f\"\\nGraph Statistics:\")\n",
                "print(f\"Tafsir nodes: {tafsir_count}\")\n",
                "print(f\"HAS_TAFSIR relationships: {rel_count}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Example Queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Example query: Find tafsirs for a specific verse\n",
                "print(\"Example: Tafsirs for verse 1:1\")\n",
                "result = conn.execute(\"\"\"\n",
                "MATCH (v:Verse)-[:HAS_TAFSIR]->(t:Tafsir)\n",
                "WHERE v.verse_key = '1:1'\n",
                "RETURN t.source, t.language, substring(t.text, 0, 100) as text_preview\n",
                "\"\"\")\n",
                "result.get_as_df()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Example query: Find verses with tafsir in Indonesian\n",
                "print(\"Example: Verses with Indonesian tafsir\")\n",
                "result = conn.execute(\"\"\"\n",
                "MATCH (v:Verse)-[:HAS_TAFSIR]->(t:Tafsir)\n",
                "WHERE t.language = 'indonesian'\n",
                "RETURN v.verse_key, t.source\n",
                "LIMIT 5\n",
                "\"\"\")\n",
                "result.get_as_df()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Example query: Count tafsirs by source and language\n",
                "print(\"Example: Count of tafsirs by source and language\")\n",
                "result = conn.execute(\"\"\"\n",
                "MATCH (t:Tafsir)\n",
                "RETURN t.source, t.language, count(*) as count\n",
                "ORDER BY count DESC\n",
                "\"\"\")\n",
                "result.get_as_df()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Example query: Find verses with the most tafsirs\n",
                "print(\"Example: Verses with the most tafsirs\")\n",
                "result = conn.execute(\"\"\"\n",
                "MATCH (v:Verse)-[:HAS_TAFSIR]->(t:Tafsir)\n",
                "RETURN v.verse_key, v.text, count(t) as tafsir_count\n",
                "ORDER BY tafsir_count DESC\n",
                "LIMIT 10\n",
                "\"\"\")\n",
                "result.get_as_df()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "print(\"\\nTafsir data integration complete!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}